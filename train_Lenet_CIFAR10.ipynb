{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from Lenet import Lenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=datasets.CIFAR10(root='./dataset',train=True,download=False,\n",
    "                           transform=transforms)\n",
    "train_loader=DataLoader(train_set,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set=datasets.CIFAR10(root='./dataset',train=False,download=False,\n",
    "                         transform=transforms)\n",
    "val_loader=DataLoader(val_set,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img,val_lab=iter(val_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Lenet().to(device)\n",
    "loss_function=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,    0] train_loss:0.001\n",
      "[0,  500] train_loss:0.501\n",
      "[0, 1000] train_loss:0.540\n",
      "[0, 1500] train_loss:0.547\n",
      "[1,    0] train_loss:0.001\n",
      "[1,  500] train_loss:0.463\n",
      "[1, 1000] train_loss:0.510\n",
      "[1, 1500] train_loss:0.520\n",
      "[2,    0] train_loss:0.001\n",
      "[2,  500] train_loss:0.431\n",
      "[2, 1000] train_loss:0.464\n",
      "[2, 1500] train_loss:0.501\n",
      "[3,    0] train_loss:0.001\n",
      "[3,  500] train_loss:0.404\n",
      "[3, 1000] train_loss:0.450\n",
      "[3, 1500] train_loss:0.468\n",
      "[4,    0] train_loss:0.001\n",
      "[4,  500] train_loss:0.367\n",
      "[4, 1000] train_loss:0.406\n",
      "[4, 1500] train_loss:0.458\n",
      "[5,    0] train_loss:0.001\n",
      "[5,  500] train_loss:0.350\n",
      "[5, 1000] train_loss:0.398\n",
      "[5, 1500] train_loss:0.406\n",
      "[6,    0] train_loss:0.001\n",
      "[6,  500] train_loss:0.327\n",
      "[6, 1000] train_loss:0.356\n",
      "[6, 1500] train_loss:0.407\n",
      "[7,    0] train_loss:0.000\n",
      "[7,  500] train_loss:0.307\n",
      "[7, 1000] train_loss:0.338\n",
      "[7, 1500] train_loss:0.380\n",
      "[8,    0] train_loss:0.001\n",
      "[8,  500] train_loss:0.292\n",
      "[8, 1000] train_loss:0.316\n",
      "[8, 1500] train_loss:0.356\n",
      "[9,    0] train_loss:0.001\n",
      "[9,  500] train_loss:0.268\n",
      "[9, 1000] train_loss:0.311\n",
      "[9, 1500] train_loss:0.343\n",
      "Finish Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    running_loss=0\n",
    "    for step,data in enumerate(train_loader):\n",
    "        x,y=data\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "        y_predict=model(x)\n",
    "        loss=loss_function(y_predict,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        \n",
    "        if step %500==0:\n",
    "                print('[%d,%5d] train_loss:%.3f'%(epoch,step,running_loss/500))\n",
    "                running_loss=0\n",
    "print('Finish Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path='./Lenet.pth'\n",
    "torch.save(model.state_dict(),save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
